{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bHGihPrKMAJa",
    "outputId": "b35381df-a180-4808-ca0c-995ea6c0afdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J75s2hPMMC7-",
    "outputId": "ec290a3f-529b-49df-eda4-18c6a81491d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nejGa1C50IrM"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IxbVpBuAYrCO",
    "outputId": "9008b76a-3499-4833-f2c2-4fe369a0f511"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from IPython.display import clear_output\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Wg8-7D2YrCT"
   },
   "outputs": [],
   "source": [
    "#data frame with the filtered topic labels and features that characterize each data entry:\n",
    "\n",
    "file = open(\"tfidf_topics.pkl\",'rb')\n",
    "df = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of topics')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(font_scale=0.7)\n",
    "df['text_tokens'].value_counts().plot(kind='bar', figsize=(9, 6), rot=0)\n",
    "plt.xlabel(\"Topic labels\", labelpad=14)\n",
    "plt.ylabel(\"Number of topics\", labelpad=14)\n",
    "#plt.title(\"Histogram showing frequency of topics in the dataset\", y=1.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72C2BE10D3673447A6D596E12C0523DA    502\n",
       "3396F36ADFF2A01A34C0CB3486CABFEE    388\n",
       "5049F4AC51D668D064214377EB38A8D3    320\n",
       "3FC1A3B3B9C8D1BD6673C3B5B65A6E91    308\n",
       "F1D8FA7C91B5EE653330E80D48C77AD1    297\n",
       "                                   ... \n",
       "99182399BD0A2044EFE905F6F90D5278     21\n",
       "25DDB40147D5A0267158FF2142B5BA74     21\n",
       "3DF7577EA3128788FE3834E676DD25F9     21\n",
       "DD982926F3C94DF49972A1843CA6E706     21\n",
       "1B776436E2C4E41CA201A14F7439CEA0     21\n",
       "Name: engaging_user_id, Length: 107017, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet count for all the users considered\n",
    "df['engaging_user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbFWA-NBYrCc"
   },
   "outputs": [],
   "source": [
    "#Convert date to yyyy-mm-dd hh:mm:ss format\n",
    "import datetime\n",
    "df['tweet_timestamp'] = df[\"tweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0qCQt8hYrCp"
   },
   "outputs": [],
   "source": [
    "t1 = df[(df[\"tweet_timestamp\"] >= '2020-02-05 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-06 06:00:00')]\n",
    "t2 = df[(df[\"tweet_timestamp\"] >= '2020-02-06 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-06 18:00:00')]\n",
    "t3 = df[(df[\"tweet_timestamp\"] >= '2020-02-06 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-07 06:00:00')]\n",
    "t4 = df[(df[\"tweet_timestamp\"] >= '2020-02-07 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-07 18:00:00')]\n",
    "t5 = df[(df[\"tweet_timestamp\"] >= '2020-02-07 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-08 06:00:00')]\n",
    "t6 = df[(df[\"tweet_timestamp\"] >= '2020-02-08 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-08 18:00:00')]\n",
    "t7 = df[(df[\"tweet_timestamp\"] >= '2020-02-08 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-09 06:00:00')]\n",
    "t8 = df[(df[\"tweet_timestamp\"] >= '2020-02-09 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-09 18:00:00')]\n",
    "t9 = df[(df[\"tweet_timestamp\"] >= '2020-02-09 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-10 06:00:00')]\n",
    "t10 = df[(df[\"tweet_timestamp\"] >= '2020-02-10 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-10 18:00:00')]\n",
    "t11 = df[(df[\"tweet_timestamp\"] >= '2020-02-10 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-11 06:00:00')]\n",
    "t12 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-11 18:00:00')]\n",
    "t13 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 06:00:00')]\n",
    "t14 = df[(df[\"tweet_timestamp\"] >= '2020-02-12 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 18:00:00')]\n",
    "\n",
    "# Each time period is 12 hrs\n",
    "# Engagement frequency of user is from time periods t1 to t12 during training\n",
    "# Recent history of user is considered from time periods t9 to t12 training \n",
    "# Current time period is considered as t13\n",
    "# Testing will be carried out on time period t14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-UI0k4SYrCr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns = ['reply_timestamp','tweet_timestamp', 'tweet_id',\"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsXfXWMrYrCt"
   },
   "outputs": [],
   "source": [
    "#Recent history t9 to t12 for training\n",
    "\n",
    "t9['retweet'] = np.where(pd.notnull(t9['retweet_timestamp']), 1, 0)\n",
    "t9.drop(columns, axis=1,inplace=True)\n",
    "t_9 = t9.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "t9_history = t_9.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "t9_history.fillna(0,inplace = True)\n",
    "history_t9 = pd.DataFrame(t9_history.to_records())\n",
    "for col in history_t9.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    history_t9.loc[history_t9[col] > 1, col] = 1\n",
    "\n",
    "t10['retweet'] = np.where(pd.notnull(t10['retweet_timestamp']), 1, 0)\n",
    "t10.drop(columns, axis=1,inplace=True)\n",
    "t_10 = t10.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "t10_history = t_10.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "t10_history.fillna(0,inplace = True)\n",
    "history_t10 = pd.DataFrame(t10_history.to_records())\n",
    "for col in history_t10.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    history_t10.loc[history_t10[col] > 1, col] = 1\n",
    "\n",
    "t11['retweet'] = np.where(pd.notnull(t11['retweet_timestamp']), 1, 0)\n",
    "t11.drop(columns, axis=1,inplace=True)\n",
    "t_11 = t11.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "t11_history = t_11.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "t11_history.fillna(0,inplace = True)\n",
    "history_t11 = pd.DataFrame(t11_history.to_records())\n",
    "for col in history_t11.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    history_t11.loc[history_t11[col] > 1, col] = 1\n",
    "\n",
    "\n",
    "t12['retweet'] = np.where(pd.notnull(t12['retweet_timestamp']), 1, 0)\n",
    "t12.drop(columns, axis=1,inplace=True)\n",
    "t_12 = t12.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "t12_history = t_12.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "t12_history.fillna(0,inplace = True)\n",
    "history_t12 = pd.DataFrame(t12_history.to_records())\n",
    "for col in history_t12.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    history_t12.loc[history_t12[col] > 1, col] = 1\n",
    "\n",
    "    \n",
    "t13['retweet'] = np.where(pd.notnull(t13['retweet_timestamp']), 1, 0)\n",
    "t13.drop(columns, axis=1,inplace=True)\n",
    "t_13 = t13.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "t13_history = t_13.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "t13_history.fillna(0,inplace = True)\n",
    "history_t13 = pd.DataFrame(t13_history.to_records())\n",
    "for col in history_t13.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    history_t13.loc[history_t13[col] > 1, col] = 1\n",
    "\n",
    "\n",
    "t14['retweet'] = np.where(pd.notnull(t14['retweet_timestamp']), 1, 0)\n",
    "t14.drop(columns, axis=1,inplace=True)\n",
    "t_14 = t14.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "test_info = t_14.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "test_info.fillna(0,inplace = True)\n",
    "test = pd.DataFrame(test_info.to_records())\n",
    "for col in test.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    test.loc[test[col] > 1, col] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGf7A5I0YrCw"
   },
   "outputs": [],
   "source": [
    "#Engagement frequency for testing time\n",
    "eng_frequency = df[df[\"tweet_timestamp\"] < '2020-02-12 6:00:00']\n",
    "eng_frequency['retweet'] = np.where(pd.notnull(eng_frequency['retweet_timestamp']), 1, 0)\n",
    "columns = ['tweet_timestamp', 'tweet_id', 'reply_timestamp', \"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "eng_frequency.drop(columns, axis=1,inplace=True)\n",
    "engagement_history = eng_frequency.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "input_engagement_history = engagement_history.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "input_engagement_history.fillna(0,inplace = True)\n",
    "history_frequency = pd.DataFrame(input_engagement_history.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engagement frequency for training time\n",
    "eng_frequency_train = df[df[\"tweet_timestamp\"] < '2020-02-11 18:00:00']\n",
    "eng_frequency_train['retweet'] = np.where(pd.notnull(eng_frequency_train['retweet_timestamp']), 1, 0)\n",
    "columns = ['tweet_timestamp', 'tweet_id', 'reply_timestamp', \"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "eng_frequency_train.drop(columns, axis=1,inplace=True)\n",
    "engagement_history_train = eng_frequency_train.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "input_engagement_history_train = engagement_history_train.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "input_engagement_history_train.fillna(0,inplace = True)\n",
    "history_frequency_train = pd.DataFrame(input_engagement_history_train.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cz4nCHWqFW8I"
   },
   "outputs": [],
   "source": [
    "\n",
    "left_out_rows_t9 = history_frequency[~history_frequency['engaging_user_id'].isin(history_t9['engaging_user_id'])]\n",
    "for col in left_out_rows_t9.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_t9[col].values[:] = 0\n",
    "final_history_t9 = history_t9.append(left_out_rows_t9)\n",
    "final_history_t9 = final_history_t9.sort_values('engaging_user_id')\n",
    "final_history_t9.reset_index(drop=True, inplace=True)\n",
    "\n",
    "left_out_rows_t10 = history_frequency[~history_frequency['engaging_user_id'].isin(history_t10['engaging_user_id'])]\n",
    "for col in left_out_rows_t10.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_t10[col].values[:] = 0\n",
    "final_history_t10 = history_t10.append(left_out_rows_t10)\n",
    "final_history_t10 = final_history_t10.sort_values('engaging_user_id')\n",
    "final_history_t10.reset_index(drop=True, inplace=True)\n",
    "\n",
    "left_out_rows_t11 = history_frequency[~history_frequency['engaging_user_id'].isin(history_t11['engaging_user_id'])]\n",
    "for col in left_out_rows_t11.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_t11[col].values[:] = 0\n",
    "final_history_t11 = history_t11.append(left_out_rows_t11)\n",
    "final_history_t11 = final_history_t11.sort_values('engaging_user_id')\n",
    "final_history_t11.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "left_out_rows_t12 = history_frequency[~history_frequency['engaging_user_id'].isin(history_t12['engaging_user_id'])]\n",
    "for col in left_out_rows_t12.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_t12[col].values[:] = 0\n",
    "final_history_t12 = history_t12.append(left_out_rows_t12)\n",
    "final_history_t12 = final_history_t12.sort_values('engaging_user_id')\n",
    "final_history_t12.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jdyIEsaYrCy"
   },
   "outputs": [],
   "source": [
    "\n",
    "#label for training\n",
    "left_out_rows_t13 = history_frequency[~history_frequency['engaging_user_id'].isin(history_t13['engaging_user_id'])]\n",
    "for col in left_out_rows_t13.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_t13[col].values[:] = 0\n",
    "final_history_t13 = history_t13.append(left_out_rows_t13)\n",
    "final_history_t13 = final_history_t13.sort_values('engaging_user_id')\n",
    "final_history_t13.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#label for testing\n",
    "left_out_rows = history_frequency[~history_frequency['engaging_user_id'].isin(test['engaging_user_id'])]\n",
    "for col in left_out_rows.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows[col].values[:] = 0\n",
    "final_test = test.append(left_out_rows)\n",
    "final_test = final_test.sort_values('engaging_user_id')\n",
    "final_test.reset_index(drop=True, inplace=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNp-t1vkQXiq"
   },
   "outputs": [],
   "source": [
    "#dataframes with engagement histories  \n",
    "from functools import reduce\n",
    "recent_history = reduce(lambda x,y: pd.merge(x,y, on='engaging_user_id', how='outer'), [final_history_t9, final_history_t10, final_history_t11, final_history_t12])\n",
    "recent_history_test = reduce(lambda x,y: pd.merge(x,y, on='engaging_user_id', how='outer'), [final_history_t10, final_history_t11, final_history_t12, final_history_t13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PelCIh_vH8fv"
   },
   "outputs": [],
   "source": [
    "history_frequency = history_frequency.sort_values('engaging_user_id')\n",
    "history_frequency_train = history_frequency_train.sort_values('engaging_user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5waABduYrC-"
   },
   "outputs": [],
   "source": [
    "#topic recommendations generation for training and testing.\n",
    "\n",
    "time = df[(df[\"tweet_timestamp\"] >= '2020-02-12 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 18:00:00')]\n",
    "left = time[time['retweet_timestamp'] >= 0]\n",
    "time['retweet_timestamp'].fillna(0,inplace=True)\n",
    "\n",
    "left['retweet_timestamp'] = left[\"retweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "time = pd.concat([time,left]).drop_duplicates(keep=False)\n",
    "time['retweet_timestamp'] = time['tweet_timestamp']\n",
    "final = pd.concat([time,left])\n",
    "\n",
    "final = final.sort_values(['engaging_user_id', 'retweet_timestamp'], ascending=[True, False])\n",
    "final = final.reset_index(drop=True)\n",
    "\n",
    "columns = ['tweet_id',\"reply_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "final.drop(columns, axis=1,inplace=True)\n",
    "\n",
    "\n",
    "time_1 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 06:00:00')]\n",
    "left_1 = time_1[time_1['retweet_timestamp'] >= 0]\n",
    "time_1['retweet_timestamp'].fillna(0,inplace=True)\n",
    "\n",
    "left_1['retweet_timestamp'] = left_1[\"retweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "time_1 = pd.concat([time_1,left_1]).drop_duplicates(keep=False)\n",
    "time_1['retweet_timestamp'] = time_1['tweet_timestamp']\n",
    "initial = pd.concat([time_1,left_1])\n",
    "\n",
    "initial = initial.sort_values(['engaging_user_id', 'retweet_timestamp'], ascending=[True, False])\n",
    "initial = initial.reset_index(drop=True)\n",
    "\n",
    "columns = ['tweet_id',\"reply_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "initial.drop(columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hYN4tkv7vCT"
   },
   "outputs": [],
   "source": [
    "# We consider the positive examples for topic recommendations from all the tweets posted during the active states and vice versa. \n",
    "# An active state is defined as a period between when a tweet is published and engaged\n",
    "\n",
    "\n",
    "#Function action_recommend for determining the active states\n",
    "def active_recommend(x):\n",
    "    g = 3\n",
    "    for index, row in x.iterrows():\n",
    "      if g != 10 :\n",
    "        a = row['engaging_user_id']\n",
    "        b = row['tweet_timestamp']\n",
    "        c = row['retweet_timestamp']\n",
    "        p = 0\n",
    "        if b != c :\n",
    "          g = 10\n",
    "      if (row['tweet_timestamp'] != row['retweet_timestamp']):\n",
    "          p = 1\n",
    "          d = row['engaging_user_id']\n",
    "          e = row['tweet_timestamp']\n",
    "          f = row['retweet_timestamp']\n",
    "      elif row['tweet_timestamp'] == row['retweet_timestamp']:\n",
    "          if row['engaging_user_id'] == a:\n",
    "            p = 0\n",
    "          elif row['engaging_user_id'] == d:\n",
    "            if (row['tweet_timestamp'] >= e) & (row['tweet_timestamp'] <= f):\n",
    "              p = 1\n",
    "            else:\n",
    "              p = 0\n",
    "      x.loc[index,'recommend'] = p\n",
    "    return final\n",
    "    }\n",
    "final = active_recommend(final)    # Test Recommendations \n",
    "inital = active_recommend(initial) # Training Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFNidgLQIuj1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    287758\n",
       "0.0    105948\n",
       "Name: recommend, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    221141\n",
       "0.0     71676\n",
       "Name: recommend, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial['recommend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['tweet_timestamp','retweet_timestamp']\n",
    "final.drop(column, axis=1,inplace=True)\n",
    "initial.drop(column, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_1 = final.groupby(['engaging_user_id', 'text_tokens'])[['recommend']].agg('sum')\n",
    "final_2 = final_1.pivot_table(index='engaging_user_id', columns='text_tokens', values='recommend')\n",
    "final_2.fillna(0,inplace = True)\n",
    "final_3 = pd.DataFrame(final_2.to_records())\n",
    "\n",
    "for col in final_3.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    final_3.loc[final_3[col] > 1, col] = 1\n",
    "    \n",
    "    \n",
    "left_out_rows_f = history_frequency[~history_frequency['engaging_user_id'].isin(final_3['engaging_user_id'])]\n",
    "for col in left_out_rows_f.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_f[col].values[:] = 0\n",
    "final_4 = final_3.append(left_out_rows_f)\n",
    "recommend_test = final_4.sort_values('engaging_user_id')\n",
    "recommend_test.reset_index(drop=True, inplace=True)  #Dataframe with topic recommendation during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_1 = initial.groupby(['engaging_user_id', 'text_tokens'])[['recommend']].agg('sum')\n",
    "initial_2 = initial_1.pivot_table(index='engaging_user_id', columns='text_tokens', values='recommend')\n",
    "initial_2.fillna(0,inplace = True)\n",
    "initial_3 = pd.DataFrame(final_2.to_records())\n",
    "\n",
    "for col in initial_3.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    initial_3.loc[final_3[col] > 1, col] = 1\n",
    "    \n",
    "left_out_rows_g = history_frequency[~history_frequency['engaging_user_id'].isin(final_3['engaging_user_id'])]\n",
    "for col in left_out_rows_g.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_f[col].values[:] = 0\n",
    "initial_4 = initial_3.append(left_out_rows_f)\n",
    "recommend = initial_4.sort_values('engaging_user_id')\n",
    "recommend.reset_index(drop=True, inplace=True)      #Dataframe with topic recommendation during training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gq6BFzyYrDB"
   },
   "outputs": [],
   "source": [
    "X_recent_2 = recent_history.drop('engaging_user_id', axis=1).values\n",
    "X_recent_1 = X_recent_2.reshape(-1,50,4)\n",
    "\n",
    "X_recent_2_test = recent_history_test.drop('engaging_user_id', axis=1).values\n",
    "X_recent_1_test = X_recent_2_test.reshape(-1,50,4)\n",
    "\n",
    "\n",
    "\n",
    "X_freq_1 = history_frequency.drop('engaging_user_id', axis=1).values\n",
    "X_freq_1_train = history_frequency_train.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "\n",
    "X_recommend_1 = recommend.drop('engaging_user_id', axis=1).values\n",
    "X_recommend_t = recommend_test.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "y_1 = final_history_t13.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "y_t = final_test.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "#INPUTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recent = torch.FloatTensor(X_recent_1)              #Recent Engagement History tensor input for training\n",
    "X_freq = torch.FloatTensor(X_freq_1_train)            #Engagement Frequency tensor input for training\n",
    "X_recommend = torch.FloatTensor(X_recommend_1)        #Topic Recommendation tensor input for training\n",
    "y = torch.FloatTensor(y_1)                            #Engagement output tensor input for training\n",
    "\n",
    "\n",
    "X_recent_test = torch.FloatTensor(X_recent_1_test)    #Recent Engagement History tensor input for testing\n",
    "X_freq_test = torch.FloatTensor(X_freq_1)             #Engagement Frequency tensor input for testing\n",
    "X_recommend_test = torch.FloatTensor(X_recommend_t)   #Topic Recommendation tensor input for testing\n",
    "Y_test = torch.FloatTensor(y_t)                       #Engagement output tensor input for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_freq = F.normalize(X_freq, p=2, dim=1)              #Normalized Engagement Frequency tensor input for training\n",
    "X_freq_test = F.normalize(X_freq_test, p=2, dim=1)    #Normalized Engagement Frequency tensor input for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpnoFF4seqrF"
   },
   "outputs": [],
   "source": [
    "final_test['1'].value_counts()\n",
    "b = []\n",
    "for i in range(50):\n",
    "      b.append(final_history_t13[str(i)].sum())\n",
    "np.array(b)\n",
    "c = 107017*np.ones((50))\n",
    "weights  = torch.tensor((c-np.array(b))/np.array(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 20\n",
    "L = 10\n",
    "class DNN_f(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #frequency input\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=L)\n",
    "\n",
    "        #history input 32 * 50 * 4\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = filters, kernel_size = (1,4) ,stride = 1)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels = filters, out_channels = filters, kernel_size = (50-L+1,1) ,stride = 1)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels = filters, out_channels = filters, kernel_size =(50-L+1,1), stride =1)\n",
    "\n",
    "\n",
    "        #recommend input\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=L)\n",
    "        \n",
    "        #final linear\n",
    "        self.conv4 = nn.Conv2d(in_channels = 1, out_channels=1, kernel_size=(1, 5+2*(filters)), stride = 1) \n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features=45, out_features=1)\n",
    "\n",
    " \n",
    "    def forward(self, x, y, z, a):\n",
    "        x1 = self.fc1(x)      ### EH\n",
    "        x2 = F.linear(x1, self.fc1.weight.t())  #### EH BAR\n",
    "\n",
    "        \n",
    "        y_ = y.view(-1,1,50,4)\n",
    "        y1 = self.conv1(y_)\n",
    "        y1 = self.leaky(y1)\n",
    "        y2 = y1.view(-1,50,filters)   ####   ET       \n",
    "        y1 = self.conv2(y1)\n",
    "        y1 = self.conv3(y1)\n",
    "        y3 = y1.view(-1,50,filters)   ####   ETBAR\n",
    "        print(y.shape)\n",
    "        print(y2.shape)\n",
    "        \n",
    "        z1 = self.fc3(z)    ####  DT\n",
    "        z2 = F.linear(z1, self.fc3.weight.t())    #### DTBAR\n",
    "\n",
    "        \n",
    "        w = torch.stack((x, x2,z, z2), dim=2)\n",
    "        v = torch.cat((y2,y3),dim =2)\n",
    "        u = torch.cat((w,v),dim=2)\n",
    "        a = a.view(-1,50,1)\n",
    "        r = torch.cat((a,u),dim = 2)\n",
    "        \n",
    "        #r = r.view(-1,1,50,5+2*(filters))\n",
    "        #t = self.conv4(r)\n",
    "        #s = t.view(-1,50)\n",
    "        \n",
    "        r = r.view(-1,50,5+2*(filters))\n",
    "        print(r.shape)\n",
    "        t = self.fc4(r)\n",
    "        s = t.view(-1,50)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 20\n",
    "L = 10\n",
    "class DNN_l(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #frequency input\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=L)\n",
    "\n",
    "        #history input 32 * 50 * 4\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = filters, kernel_size = (1,4) ,stride = 1)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels = filters, out_channels = filters, kernel_size = (50-L+1,1) ,stride = 1)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels = filters, out_channels = filters, kernel_size =(50-L+1,1), stride =1)\n",
    "\n",
    "\n",
    "        #recommend input\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=L)\n",
    "        \n",
    "        #final linear\n",
    "        self.conv4 = nn.Conv2d(in_channels = 1, out_channels=1, kernel_size=(1, 5+2*(filters)), stride = 1) \n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features=49, out_features=500)\n",
    "        \n",
    "        self.fc5 = nn.Linear(in_features=500, out_features=100)\n",
    "        \n",
    "        self.fc6 = nn.Linear(in_features=100, out_features=1)\n",
    "        \n",
    "        \n",
    "\n",
    " \n",
    "    def forward(self, x, y, z, a):\n",
    "        x1 = self.fc1(x)      ### EH\n",
    "        x2 = F.linear(x1, self.fc1.weight.t())  #### EH BAR\n",
    "\n",
    "        \n",
    "        y_ = y.view(-1,1,50,4)\n",
    "        y1 = self.conv1(y_)\n",
    "        y1 = self.leaky(y1)\n",
    "        y2 = y1.view(-1,50,filters)   ####   ET       \n",
    "        y1 = self.conv2(y1)\n",
    "        y1 = self.conv3(y1)\n",
    "        y3 = y1.view(-1,50,filters)   ####   ETBAR\n",
    "        \n",
    "        z1 = self.fc3(z)    ####  DT\n",
    "        z2 = F.linear(z1, self.fc3.weight.t())    #### DTBAR\n",
    "\n",
    "        \n",
    "        w = torch.stack((x, x2,z, z2), dim=2)\n",
    "        v = torch.cat((y2,y3),dim =2)\n",
    "        u = torch.cat((w,v),dim=2)\n",
    "        a = a.view(-1,50,1)\n",
    "        r = torch.cat((a,u),dim = 2)\n",
    "        \n",
    "        #r = r.view(-1,50,5+2*(filters))\n",
    "        #r = torch.cat((r,y),dim=2)\n",
    "        #r = r.view(-1,1,50,5+2*(filters))\n",
    "        #t = self.conv4(r)\n",
    "        #s = t.view(-1,50)\n",
    "        \n",
    "        \n",
    "        r = r.view(-1,50,5+2*(filters))\n",
    "        r = torch.cat((r,y),dim=2)\n",
    "        t = self.fc4(r)\n",
    "        t = self.fc5(t)\n",
    "        t = self.fc6(t)\n",
    "        s = t.view(-1,50)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones([32, 50], dtype=torch.float64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M5PLdzGYrDO"
   },
   "outputs": [],
   "source": [
    "model = DNN_f()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYXUuJAjYrDQ"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "#loss_func = nn.BCEWithLogitsLoss(pos_weight = weights, reduction = 'sum').cuda()\n",
    "loss_func = nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loss = 0\n",
    "losses = []\n",
    "steps = []\n",
    "step = 0\n",
    "count = 0\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKAPwzquMI6f"
   },
   "outputs": [],
   "source": [
    "X_indicator = torch.ones([107017, 50])\n",
    "import time\n",
    "start_time = time.time()\n",
    "train_dataset = TensorDataset(X_freq, X_recent, X_recommend, y, X_indicator)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    model.train()\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        freq, recent, recommend, labels, indicator = tuple(t.to(device)for t in batch_data)\n",
    "        probas = model(freq, recent, recommend, indicator)\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "\n",
    "\n",
    "        #clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"{0}/{1} loss: {2} \".format(step_num, len(y)/BATCH_SIZE, train_loss / (count + 1)))\n",
    "        print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        losses.append(batch_loss.item())\n",
    "        steps.append(step)\n",
    "        step += 1\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeAm0QIHYrDV"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#torch.save({'state_dict': model.state_dict()}, 'checkpoint.pth.tar')\n",
    "\n",
    "#model = describe_model()\n",
    "#checkpoint = torch.load('checkpoint.pth.tar')\n",
    "#model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    logits_train = model(X_freq.to(device), X_recent.to(device), X_recommend.to(device), X_indicator.to(device)).to('cpu')\n",
    "    logits_test = model(X_freq_test.to(device), X_recent_test.to(device), X_recommend_test.to(device), X_indicator.to(device)).to('cpu')\n",
    "    numpy_logits_train = logits_train.detach().numpy()\n",
    "    numpy_logits_test = logits_test.detach().numpy()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# custom function\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# define vectorized sigmoid\n",
    "sigmoid_v = np.vectorize(sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting logits to probabilities\n",
    "numpy_probas_test = sigmoid_v(numpy_logits_test)\n",
    "numpy_probas_train = sigmoid_v(numpy_logits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test.numpy(),numpy_probas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Metrics          \n",
    "def binary_classification_performance(y_test, y_pred):\n",
    "    tp, fp, fn, tn = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = round(accuracy_score(y_pred = y_pred, y_true = y_test),2)\n",
    "    precision = round(precision_score(y_pred = y_pred, y_true = y_test),2)\n",
    "    recall = round(recall_score(y_pred = y_pred, y_true = y_test),2)\n",
    "    f1_score = round(2*precision*recall/(precision + recall),2)\n",
    "    specificity = round(tn/(tn+fp),2)\n",
    "    npv = round(tn/(tn+fn),2)\n",
    "\n",
    "\n",
    "    result = pd.DataFrame({'Accuracy' : [accuracy],\n",
    "                         'Precision (or PPV)' : [precision],\n",
    "                         'Recall (senitivity or TPR)' : [recall],\n",
    "                         'f1 score' : [f1_score],\n",
    "                         'Specificty (or TNR)': [specificity],\n",
    "                         'NPV' : [npv],\n",
    "                         'True Positive' : [tp],\n",
    "                         'True Negative' : [tn],\n",
    "                         'False Positive':[fp],\n",
    "                         'False Negative':[fn]})\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = []\n",
    "roc = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), numpy_probas_test[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    roc.append(roc_auc)\n",
    "    thresh.append(optimal_threshold)\n",
    "    \n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (threshold[ix], gmeans[ix]))\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(roc)/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "\treturn (pos_probs >= threshold).astype('int')\n",
    "\n",
    "for i in range(50):\n",
    "    numpy_probas_test[:,i] = to_labels(numpy_probas_test[:,i],thresh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(50):\n",
    "    scores.append(binary_classification_performance(Y_test[:,i].numpy(),numpy_probas_test[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.concat(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(Y_test.numpy(), numpy_probas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting engagement frequencies from tensor to numpy array\n",
    "\n",
    "X_freq_1 = X_freq.numpy()\n",
    "X_freq_1_test = X_freq_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_train_p = []\n",
    "empty_test_p = []\n",
    "for i in range(50):\n",
    "    recent_lm_train = X_recent_2[:,[i,i+50,i+100,i+150]]     #Engagement history by topic as input for training\n",
    "    freq_lm_train = X_freq_1[:,i]                            #Engagement frequncy by topic as input for training\n",
    "    recommend_lm_train = X_recommend_1[:,i]                  #Recommendations by topic as input for training\n",
    "    \n",
    "    recent_lm_test = X_recent_2_test[:,[i,i+50,i+100,i+150]] #Engagement history by topic as input for testing\n",
    "    freq_lm_test = X_freq_1_test[:,i]                        #Engagement frequncy by topic as input for testing\n",
    "    recommend_lm_test = X_recommend_t[:,i]                   #Recommendations by topic as input for testing\n",
    "\n",
    "\n",
    "    y_lm_train = y_1[:,i]                                    #Engagement labels\n",
    "\n",
    "    X = np.column_stack([recent_lm_train,freq_lm_train,recommend_lm_train])  #Concatenated input features for training\n",
    "\n",
    "    #LR = LogisticRegression(class_weight=\"balanced\")\n",
    "    LR = LogisticRegression()\n",
    "\n",
    "    LR.fit(X,y_lm_train)\n",
    "    \n",
    "    X_test = np.column_stack([recent_lm_test,freq_lm_test,recommend_lm_test]) #Concatenated input features for testing\n",
    "    \n",
    "    empty_train_p.append((LR.predict_proba(X)[:,1]))\n",
    "       \n",
    "    empty_test_p.append((LR.predict_proba(X_test)[:,1]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr_train_p = np.transpose(np.array(empty_train_p))  #Predictions for training data\n",
    "prediction_lr_test_p = np.transpose(np.array(empty_test_p))    #Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_t,prediction_lr_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresh_lr = []\n",
    "roc_lr = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), prediction_lr_test_p[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    thresh_lr.append(optimal_threshold)\n",
    "    roc_lr.append(roc_auc)\n",
    "    \n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (threshold[ix], gmeans[ix]))\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(roc_lr)/50  #Average AUC-ROC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    prediction_lr_test_p[:,i] = to_labels(prediction_lr_test_p[:,i],thresh_lr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(Y_test.numpy(), prediction_lr_test_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lr = []\n",
    "for i in range(50):\n",
    "    scores_lr.append(binary_classification_performance(Y_test[:,i].numpy(),prediction_lr_test_p[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lr = pd.concat(scores_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_train_1p = []\n",
    "empty_test_1p = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    recent_lm_train = X_recent_2[:,[i,i+50,i+100,i+150]]\n",
    "    freq_lm_train = X_freq_1[:,i]\n",
    "    recommend_lm_train = X_recommend_1[:,i]\n",
    "    \n",
    "    recent_lm_test = X_recent_2_test[:,[i,i+50,i+100,i+150]]\n",
    "    freq_lm_test = X_freq_1_test[:,i]\n",
    "    recommend_lm_test = X_recommend_t[:,i]\n",
    "\n",
    "\n",
    "    y_lm_train = y_1[:,i]\n",
    "    \n",
    "\n",
    "    X = np.column_stack([recent_lm_train,freq_lm_train,recommend_lm_train])\n",
    "\n",
    "    LGBM = LGBMClassifier()\n",
    "\n",
    "    LGBM.fit(X,y_lm_train)\n",
    "    \n",
    "    X_test = np.column_stack([recent_lm_test,freq_lm_test,recommend_lm_test])\n",
    "    \n",
    "    empty_train_1.append(LGBM.predict(X))\n",
    "    \n",
    "    empty_train_1p.append((LGBM.predict_proba(X)[:,0]))\n",
    "\n",
    "    empty_test_1.append(LGBM.predict(X_test))\n",
    "    \n",
    "    empty_test_1p.append((LGBM.predict_proba(X_test)[:,0]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgbm_train = np.transpose(np.array(empty_train_1))\n",
    "prediction_lgbm_test = np.transpose(np.array(empty_test_1))\n",
    "\n",
    "prediction_lgbm_train_p = np.transpose(np.array(empty_train_1p))\n",
    "prediction_lgbm_test_p = np.transpose(np.array(empty_test_1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_lgbm_test_p\n",
    "#with open('prediction_lgbm_test_p_bce.pkl','wb') as f:\n",
    "#      pickle.dump(prediction_lgbm_test_p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test.numpy(),prediction_lgbm_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_lgbm = []\n",
    "roc_lgbm = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    #probs = model.predict_proba(X_test)\n",
    "    #preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), prediction_lgbm_test_p[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    print(optimal_threshold)\n",
    "    thresh_lgbm.append(optimal_threshold)\n",
    "    roc_lgbm.append(roc_auc)\n",
    "    \n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print('Best Threshold=%f, G-Mean=%.3f' % (threshold[ix], gmeans[ix]))\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(roc_lgbm)/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    prediction_lgbm_test_p[:,i] = to_labels(prediction_lgbm_test_p[:,i],thresh_lgbm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(Y_test.numpy(), prediction_lgbm_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lgbm = []\n",
    "for i in range(50):\n",
    "    scores_lgbm.append(binary_classification_performance(Y_test[:,i].numpy(),prediction_lgbm_test_p[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lgbm = pd.concat(scores_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_lgbm.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(X_recommend_t)\n",
    "x.sum(axis=1).value_counts()\n",
    "x['Total'] = x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x[x['Total'] >= 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = pd.DataFrame(X_freq_1_test)\n",
    "histo = pd.DataFrame(X_recent_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_new=infinity.loc[y.index,:]\n",
    "hist_new=histo.loc[y.index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dfs(x,start,end,cnt,l_):\n",
    "    if start==end:\n",
    "        return []\n",
    "    if cnt==5:\n",
    "        ans.append(l_)\n",
    "        return \n",
    "    \n",
    "    for i in range(start,end):\n",
    "        if int(x[i])==1:           \n",
    "            dfs(x,i+1,end,cnt+1,l_+[i])\n",
    "                    \n",
    "d={}\n",
    "cnt={}\n",
    "v={}\n",
    "for i in y.index:\n",
    "    p=y.loc[i,:]\n",
    "    l=list(p)\n",
    "    ans=[]\n",
    "    dfs(l,0,len(l),0,[])\n",
    "\n",
    "    v[i]=ans\n",
    "    for m in range(len(ans)):\n",
    "        n=[0]*50\n",
    "        for k in range(len(ans[m])):\n",
    "            n[ans[m][k]]=1\n",
    "        if i not in d:\n",
    "            d[i]=[]\n",
    "        d[i].append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_l=[]    \n",
    "for i in d:\n",
    "    for x in d[i]:\n",
    "        global_l.append([i]+x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_df=pd.DataFrame(global_l,columns=['User']+[i for i in range(50)]).set_index('User')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_freq =inf_new.loc[global_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_hist = hist_new.loc[global_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rec = global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_freq.shape)\n",
    "print(opt_hist.shape)\n",
    "print(opt_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_freq_T = torch.FloatTensor(opt_freq.values)\n",
    "opt_hist_T = torch.FloatTensor(opt_hist.values.reshape(-1,50,4))\n",
    "opt_rec_T = torch.FloatTensor(opt_rec.values)\n",
    "opt_indicator_T = torch.ones([505809, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_freq_T.shape)\n",
    "print(opt_hist_T.shape)\n",
    "print(opt_rec_T.shape)\n",
    "print(opt_indicator_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(opt_freq_T, opt_hist_T, opt_rec_T, opt_rec_T)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_opt = []\n",
    "for step_num, batch_data in enumerate(test_dataloader):\n",
    "        freq, recent, recommend, indicator = tuple(t.to(device)for t in batch_data)\n",
    "        logits_opt = model(freq, recent, recommend, indicator)\n",
    "        numpy_logits_opt = logits_opt.to('cpu').detach().numpy()\n",
    "        numpy_probas_opt = sigmoid_v(numpy_logits_opt)\n",
    "        probas_opt.append(pd.DataFrame(numpy_probas_opt).round(decimals=6))\n",
    "\n",
    "\n",
    "#logits_opt = model(opt_freq_T.to(device), opt_hist_T.to(device), opt_rec_T.to(device), opt_indicator_T.to(device)).to('cpu')\n",
    "#numpy_logits_opt = logits_opt.detach().numpy()\n",
    "#numpy_probas_opt = sigmoid_v(numpy_logits_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fins = pd.concat(probas_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fins = fins*opt_rec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scor = pd.DataFrame()\n",
    "#fins.sum(axis = 1)\n",
    "scor['total'] = fins.sum(axis = 1)\n",
    "#fins.values.round(9)\n",
    "scor['index'] = global_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scor.index = global_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rec_T_F = global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rec_T_F['prob'] = scor['total']\n",
    "opt_rec_T_F['ind'] = scor['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = opt_rec_T_F.sort_values('prob', ascending=False).drop_duplicates(['ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp= lp.reindex(y.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp['prob'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lp['prob']\n",
    "del lp['ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_p = pd.DataFrame(prediction_lgbm_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ding = lr_p.loc[y.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y['Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=lr_ding*y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=pd.DataFrame(np.zeros((p.shape[0],p.shape[1]))).set_index(p.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in p.index:\n",
    "    s.loc[ind,p.loc[ind].nlargest(5).index.values]=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_=s.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_rec_=opt_rec.reset_index().rename(columns={'User':'index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col=opt_rec.columns\n",
    "final=pd.merge(s_,opt_rec_,on=list(s_.columns),how='left').reset_index(drop=True).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['prob'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cplex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cvxpy\n",
    "# import numpy as np\n",
    "# print(cvxpy.installed_solvers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(30)\n",
    "# weights = np.random.randint(20, size=(50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities = numpy_probas_test[0,:]\n",
    "#probabilities = prediction_lr_test[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recomm = []\n",
    "# revenue = []\n",
    "# for i in range(len(numpy_probas_test)):\n",
    "#     probabilities = numpy_probas_test[i,:]\n",
    "\n",
    "#     selection = cvxpy.Variable(len(weights), boolean=True)\n",
    "\n",
    "#     weight_constraint = cvxpy.sum(selection, axis=0) == 5\n",
    "\n",
    "#     total_revenue = probabilities * weights * selection \n",
    "\n",
    "#     Revenue_Generation_problem = cvxpy.Problem(cvxpy.Maximize(total_revenue), [weight_constraint])\n",
    "\n",
    "#     # Solving the problem\n",
    "#     Revenue_Generation_problem.solve(solver=cvxpy.CPLEX, verbose=True)\n",
    "    \n",
    "#     revenue.append(total_revenue.value)\n",
    "#     recomm.append(selection.value)\n",
    "#     clear_output(wait=True) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('test_scores.pkl','wb') as f:\n",
    "#     pickle.dump(y_t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Product_choice_model_bucketing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
