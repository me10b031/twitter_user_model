{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bHGihPrKMAJa",
    "outputId": "b35381df-a180-4808-ca0c-995ea6c0afdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J75s2hPMMC7-",
    "outputId": "ec290a3f-529b-49df-eda4-18c6a81491d2"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nejGa1C50IrM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/skarra7/anaconda3/lib/python3.7/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: scikit-learn in /home/skarra7/anaconda3/lib/python3.7/site-packages (from lightgbm) (0.23.1)\r\n",
      "Requirement already satisfied: scipy in /home/skarra7/anaconda3/lib/python3.7/site-packages (from lightgbm) (1.4.1)\r\n",
      "Requirement already satisfied: numpy in /home/skarra7/anaconda3/lib/python3.7/site-packages (from lightgbm) (1.18.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/skarra7/anaconda3/lib/python3.7/site-packages (from scikit-learn->lightgbm) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/skarra7/anaconda3/lib/python3.7/site-packages (from scikit-learn->lightgbm) (0.14.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score,roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IxbVpBuAYrCO",
    "outputId": "9008b76a-3499-4833-f2c2-4fe369a0f511"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2180e700f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import torch\n",
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Wg8-7D2YrCT"
   },
   "outputs": [],
   "source": [
    "#data frame with the filtered topic labels and features that characterize each data entry:\n",
    "\n",
    "file = open(\"gsdmm_topics.pkl\",'rb')\n",
    "df = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72C2BE10D3673447A6D596E12C0523DA    502\n",
       "3396F36ADFF2A01A34C0CB3486CABFEE    388\n",
       "5049F4AC51D668D064214377EB38A8D3    320\n",
       "3FC1A3B3B9C8D1BD6673C3B5B65A6E91    308\n",
       "F1D8FA7C91B5EE653330E80D48C77AD1    297\n",
       "                                   ... \n",
       "72299BF202244855FD96178C95FEDBF2     21\n",
       "88B6B62A1752C6547E0EE0DF34AB2DD7     21\n",
       "05E4628760701D385318FE2A7BB1D952     21\n",
       "AA2B9CC4D183BF7701A2F75239450AE4     21\n",
       "DC5D486BE66A1C3C39B75FF2ECFE8A55     21\n",
       "Name: engaging_user_id, Length: 107017, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet count for all the users considered\n",
    "df['engaging_user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbFWA-NBYrCc"
   },
   "outputs": [],
   "source": [
    "#Convert date to yyyy-mm-dd hh:mm:ss format\n",
    "import datetime\n",
    "df['tweet_timestamp'] = df[\"tweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0qCQt8hYrCp"
   },
   "outputs": [],
   "source": [
    "t1 = df[(df[\"tweet_timestamp\"] >= '2020-02-05 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-06 06:00:00')]\n",
    "t2 = df[(df[\"tweet_timestamp\"] >= '2020-02-06 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-06 18:00:00')]\n",
    "t3 = df[(df[\"tweet_timestamp\"] >= '2020-02-06 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-07 06:00:00')]\n",
    "t4 = df[(df[\"tweet_timestamp\"] >= '2020-02-07 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-07 18:00:00')]\n",
    "t5 = df[(df[\"tweet_timestamp\"] >= '2020-02-07 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-08 06:00:00')]\n",
    "t6 = df[(df[\"tweet_timestamp\"] >= '2020-02-08 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-08 18:00:00')]\n",
    "t7 = df[(df[\"tweet_timestamp\"] >= '2020-02-08 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-09 06:00:00')]\n",
    "t8 = df[(df[\"tweet_timestamp\"] >= '2020-02-09 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-09 18:00:00')]\n",
    "t9 = df[(df[\"tweet_timestamp\"] >= '2020-02-09 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-10 06:00:00')]\n",
    "t10 = df[(df[\"tweet_timestamp\"] >= '2020-02-10 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-10 18:00:00')]\n",
    "t11 = df[(df[\"tweet_timestamp\"] >= '2020-02-10 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-11 06:00:00')]\n",
    "t12 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-11 18:00:00')]\n",
    "t13 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 18:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 06:00:00')]\n",
    "t14 = df[(df[\"tweet_timestamp\"] >= '2020-02-12 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 18:00:00')]\n",
    "\n",
    "# Each time period is 12 hrs\n",
    "# Engagement frequency of user is from time periods t1 to t11 during training\n",
    "# Recent history of user is considered from time periods t8 to t11 training \n",
    "# Training will be carrid out on time period t12\n",
    "# Validation carried out on time period t13\n",
    "# Testing will be carried out on time period t14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engagement frequency for all available timeperiod\n",
    "eng_frequency = df[df[\"tweet_timestamp\"] < '2020-02-12 6:00:00']\n",
    "eng_frequency['retweet'] = np.where(pd.notnull(eng_frequency['retweet_timestamp']), 1, 0)\n",
    "columns = ['tweet_timestamp', 'tweet_id', 'reply_timestamp', \"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "eng_frequency.drop(columns, axis=1,inplace=True)\n",
    "engagement_history = eng_frequency.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "input_engagement_history = engagement_history.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "input_engagement_history.fillna(0,inplace = True)\n",
    "history_frequency = pd.DataFrame(input_engagement_history.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Engagement frequency for testing time\n",
    "eng_frequency_test = df[df[\"tweet_timestamp\"] < '2020-02-12 6:00:00']\n",
    "eng_frequency_test['retweet'] = np.where(pd.notnull(eng_frequency_test['retweet_timestamp']), 1, 0)\n",
    "columns = ['tweet_timestamp', 'tweet_id', 'reply_timestamp', \"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "eng_frequency_test.drop(columns, axis=1,inplace=True)\n",
    "engagement_history_test = eng_frequency_test.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "input_engagement_history_test = engagement_history_test.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "input_engagement_history_test.fillna(0,inplace = True)\n",
    "history_frequency_test = pd.DataFrame(input_engagement_history_test.to_records())\n",
    "left_out_rows_xt = history_frequency[~history_frequency['engaging_user_id'].isin(history_frequency_test['engaging_user_id'])]\n",
    "for col in left_out_rows_xt.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_xt[col].values[:] = 0\n",
    "final_history_xt = history_frequency_test.append(left_out_rows_xt)\n",
    "final_history_xt = final_history_xt.sort_values('engaging_user_id')\n",
    "history_frequency_test = final_history_xt.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engagement frequency for training time\n",
    "eng_frequency_train = df[df[\"tweet_timestamp\"] < '2020-02-11 6:00:00']\n",
    "eng_frequency_train['retweet'] = np.where(pd.notnull(eng_frequency_train['retweet_timestamp']), 1, 0)\n",
    "columns = ['tweet_timestamp', 'tweet_id', 'reply_timestamp', \"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "eng_frequency_train.drop(columns, axis=1,inplace=True)\n",
    "engagement_history_train = eng_frequency_train.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "input_engagement_history_train = engagement_history_train.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "input_engagement_history_train.fillna(0,inplace = True)\n",
    "history_frequency_train = pd.DataFrame(input_engagement_history_train.to_records())\n",
    "left_out_rows_xt = history_frequency[~history_frequency['engaging_user_id'].isin(history_frequency_train['engaging_user_id'])]\n",
    "for col in left_out_rows_xt.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_xt[col].values[:] = 0\n",
    "final_history_xt = history_frequency_train.append(left_out_rows_xt)\n",
    "final_history_xt = final_history_xt.sort_values('engaging_user_id')\n",
    "history_frequency_train = final_history_xt.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-UI0k4SYrCr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "columns = ['reply_timestamp','tweet_timestamp', 'tweet_id',\"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_history(z):\n",
    "    xt = z\n",
    "    columns = ['reply_timestamp','tweet_timestamp', 'tweet_id',\"retweet_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "    xt['retweet'] = np.where(pd.notnull(xt['retweet_timestamp']), 1, 0)\n",
    "    xt.drop(columns, axis=1)\n",
    "    x_t = xt.groupby(['engaging_user_id', 'text_tokens'])[['retweet']].agg('sum')\n",
    "    xt_history = x_t.pivot_table(index='engaging_user_id', columns='text_tokens', values='retweet')\n",
    "    xt_history.fillna(0,inplace = True)\n",
    "    history_xt = pd.DataFrame(xt_history.to_records())\n",
    "    for col in history_xt.columns:\n",
    "      if col != 'engaging_user_id':\n",
    "        history_xt.loc[history_xt[col] > 1, col] = 1\n",
    "\n",
    "    left_out_rows_xt = history_frequency[~history_frequency['engaging_user_id'].isin(history_xt['engaging_user_id'])]\n",
    "    for col in left_out_rows_xt.columns:\n",
    "        if col != 'engaging_user_id':\n",
    "            left_out_rows_xt[col].values[:] = 0\n",
    "    final_history_xt = history_xt.append(left_out_rows_xt)\n",
    "    final_history_xt = final_history_xt.sort_values('engaging_user_id')\n",
    "    final_history_xt.reset_index(drop=True)\n",
    "    return final_history_xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes with engagement histories  \n",
    "from functools import reduce\n",
    "recent_history = reduce(lambda x,y: pd.merge(x,y, on='engaging_user_id', how='outer'), [final_history(t8), final_history(t9), final_history(t10), final_history(t11)])\n",
    "recent_history_test = reduce(lambda x,y: pd.merge(x,y, on='engaging_user_id', how='outer'), [final_history(t10), final_history(t11), final_history(t12), final_history(t13)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PelCIh_vH8fv"
   },
   "outputs": [],
   "source": [
    "history_frequency = history_frequency.sort_values('engaging_user_id')\n",
    "history_frequency_train = history_frequency_train.sort_values('engaging_user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5waABduYrC-"
   },
   "outputs": [],
   "source": [
    "#topic recommendations generation for training and testing.\n",
    "\n",
    "time = df[(df[\"tweet_timestamp\"] >= '2020-02-12 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-12 18:00:00')]\n",
    "#time = df[(df[\"tweet_timestamp\"] >= '2020-02-10 06:00:00') & (df[\"tweet_timestamp\"] < '2020-02-10 18:00:00')]\n",
    "left = time[time['retweet_timestamp'] >= 0]\n",
    "time['retweet_timestamp'].fillna(0,inplace=True)\n",
    "\n",
    "left['retweet_timestamp'] = left[\"retweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "time = pd.concat([time,left]).drop_duplicates(keep=False)\n",
    "time['retweet_timestamp'] = time['tweet_timestamp']\n",
    "final = pd.concat([time,left])\n",
    "\n",
    "final = final.sort_values(['engaging_user_id', 'retweet_timestamp'], ascending=[True, False])\n",
    "final = final.reset_index(drop=True)\n",
    "\n",
    "columns = ['tweet_id',\"reply_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "final.drop(columns, axis=1,inplace=True)\n",
    "\n",
    "\n",
    "time_1 = df[(df[\"tweet_timestamp\"] >= '2020-02-11 6:00:00') & (df[\"tweet_timestamp\"] < '2020-02-11 18:00:00')]\n",
    "left_1 = time_1[time_1['retweet_timestamp'] >= 0]\n",
    "time_1['retweet_timestamp'].fillna(0,inplace=True)\n",
    "\n",
    "left_1['retweet_timestamp'] = left_1[\"retweet_timestamp\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "time_1 = pd.concat([time_1,left_1]).drop_duplicates(keep=False)\n",
    "time_1['retweet_timestamp'] = time_1['tweet_timestamp']\n",
    "initial = pd.concat([time_1,left_1])\n",
    "\n",
    "initial = initial.sort_values(['engaging_user_id', 'retweet_timestamp'], ascending=[True, False])\n",
    "initial = initial.reset_index(drop=True)\n",
    "\n",
    "columns = ['tweet_id',\"reply_timestamp\",\"retweet_with_comment_timestamp\",\"like_timestamp\"]\n",
    "initial.drop(columns, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hYN4tkv7vCT"
   },
   "outputs": [],
   "source": [
    "# We consider the positive examples for topic recommendations from all the tweets posted during the active states and vice versa. \n",
    "# An active state is defined as a period between when a tweet is published and engaged\n",
    "\n",
    "\n",
    "#Function action_recommend for determining the active states\n",
    "def active_recommend(x):\n",
    "    g = 3\n",
    "    for index, row in x.iterrows():\n",
    "      p = 0  \n",
    "      if g != 10 :\n",
    "        a = row['engaging_user_id']\n",
    "        b = row['tweet_timestamp']\n",
    "        c = row['retweet_timestamp']\n",
    "        p = 0\n",
    "        if b != c :\n",
    "          g = 10\n",
    "      if (row['tweet_timestamp'] != row['retweet_timestamp']):\n",
    "          p = 1\n",
    "          d = row['engaging_user_id']\n",
    "          e = row['tweet_timestamp']\n",
    "          f = row['retweet_timestamp']\n",
    "      elif row['tweet_timestamp'] == row['retweet_timestamp']:\n",
    "          if row['engaging_user_id'] == a:\n",
    "            p = 0\n",
    "          elif row['engaging_user_id'] == d:\n",
    "            if (row['tweet_timestamp'] >= e) & (row['tweet_timestamp'] <= f):\n",
    "              p = 1\n",
    "            else:\n",
    "              p = 0\n",
    "      x.loc[index,'recommend'] = p\n",
    "    return x\n",
    "final = active_recommend(final)    # Test Recommendations \n",
    "inital = active_recommend(initial) # Training Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " column = ['tweet_timestamp','retweet_timestamp']\n",
    " final.drop(column, axis=1,inplace=True)\n",
    " initial.drop(column, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_1 = final.groupby(['engaging_user_id', 'text_tokens'])[['recommend']].agg('sum')\n",
    "final_2 = final_1.pivot_table(index='engaging_user_id', columns='text_tokens', values='recommend')\n",
    "final_2.fillna(0,inplace = True)\n",
    "final_3 = pd.DataFrame(final_2.to_records())\n",
    "\n",
    "for col in final_3.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    final_3.loc[final_3[col] > 1, col] = 1\n",
    "    \n",
    "    \n",
    "left_out_rows_f = history_frequency[~history_frequency['engaging_user_id'].isin(final_3['engaging_user_id'])]\n",
    "for col in left_out_rows_f.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_f[col].values[:] = 0\n",
    "final_4 = final_3.append(left_out_rows_f)\n",
    "recommend_test = final_4.sort_values('engaging_user_id')\n",
    "recommend_test.reset_index(drop=True, inplace=True)  #Dataframe with topic recommendation during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_1 = initial.groupby(['engaging_user_id', 'text_tokens'])[['recommend']].agg('sum')\n",
    "initial_2 = initial_1.pivot_table(index='engaging_user_id', columns='text_tokens', values='recommend')\n",
    "initial_2.fillna(0,inplace = True)\n",
    "initial_3 = pd.DataFrame(final_2.to_records())\n",
    "\n",
    "for col in initial_3.columns:\n",
    "  if col != 'engaging_user_id':\n",
    "    initial_3.loc[final_3[col] > 1, col] = 1\n",
    "    \n",
    "left_out_rows_g = history_frequency[~history_frequency['engaging_user_id'].isin(final_3['engaging_user_id'])]\n",
    "for col in left_out_rows_g.columns:\n",
    "    if col != 'engaging_user_id':\n",
    "        left_out_rows_f[col].values[:] = 0\n",
    "initial_4 = initial_3.append(left_out_rows_f)\n",
    "recommend = initial_4.sort_values('engaging_user_id')\n",
    "recommend.reset_index(drop=True, inplace=True)      #Dataframe with topic recommendation during training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gq6BFzyYrDB"
   },
   "outputs": [],
   "source": [
    "X_recent_2 = recent_history.drop('engaging_user_id', axis=1).values\n",
    "X_recent_1 = X_recent_2.reshape(-1,50,4)\n",
    "\n",
    "X_recent_2_test = recent_history_test.drop('engaging_user_id', axis=1).values\n",
    "X_recent_1_test = X_recent_2_test.reshape(-1,50,4)\n",
    "\n",
    "\n",
    "\n",
    "X_freq_1 = history_frequency_test.drop('engaging_user_id', axis=1).values\n",
    "X_freq_1_train = history_frequency_train.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "\n",
    "X_recommend_1 = recommend.drop('engaging_user_id', axis=1).values\n",
    "X_recommend_t = recommend_test.drop('engaging_user_id', axis=1).values\n",
    "\n",
    "y_1 = final_history(t12).drop('engaging_user_id', axis=1).values\n",
    "\n",
    "y_t = final_history(t14).drop('engaging_user_id', axis=1).values\n",
    "\n",
    "#INPUTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recent = torch.FloatTensor(X_recent_1)              #Recent Engagement History tensor input for training\n",
    "X_freq = torch.FloatTensor(X_freq_1_train)            #Engagement Frequency tensor input for training\n",
    "X_recommend = torch.FloatTensor(X_recommend_1)        #Topic Recommendation tensor input for training\n",
    "y = torch.FloatTensor(y_1)                            #Engagement output tensor input for training\n",
    "\n",
    "\n",
    "X_recent_test = torch.FloatTensor(X_recent_1_test)    #Recent Engagement History tensor input for testing\n",
    "X_freq_test = torch.FloatTensor(X_freq_1)             #Engagement Frequency tensor input for testing\n",
    "X_recommend_test = torch.FloatTensor(X_recommend_t)   #Topic Recommendation tensor input for testing\n",
    "Y_test = torch.FloatTensor(y_t)                       #Engagement output tensor input for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_freq = F.normalize(X_freq, p=2, dim=1)              #Normalized Engagement Frequency tensor input for training\n",
    "X_freq_test = F.normalize(X_freq_test, p=2, dim=1)    #Normalized Engagement Frequency tensor input for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 20\n",
    "L = 10\n",
    "class DNN_f(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #frequency input\n",
    "        self.fc1 = nn.Linear(in_features=50, out_features=L)\n",
    "\n",
    "        #history input 32 * 50 * 4\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = filters, kernel_size = (1,4) ,stride = 1)\n",
    "        self.leaky = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels = filters, out_channels = filters, kernel_size = (50-L+1,1) ,stride = 1)\n",
    "        self.conv3 = nn.ConvTranspose2d(in_channels = filters, out_channels = filters, kernel_size =(50-L+1,1), stride =1)\n",
    "\n",
    "\n",
    "        #recommend input\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=L)\n",
    "        \n",
    "        #final linear \n",
    "        self.conv4 = nn.Conv2d(in_channels = 1, out_channels=1, kernel_size=(1, 5+2*(filters)), stride = 1) \n",
    "        \n",
    "\n",
    " \n",
    "    def forward(self, x, y, z, a):\n",
    "        x1 = self.fc1(x)      ### EH\n",
    "        x2 = F.linear(x1, self.fc1.weight.t())  #### EH BAR\n",
    "\n",
    "        \n",
    "        y_ = y.view(-1,1,50,4)\n",
    "        y1 = self.conv1(y_)\n",
    "        y1 = self.leaky(y1)\n",
    "        y2 = y1.view(-1,50,filters)   ####   ET       \n",
    "        y1 = self.conv2(y1)\n",
    "        y1 = self.conv3(y1)\n",
    "        #y1 = self.leaky(y1)\n",
    "        y3 = y1.view(-1,50,filters)   ####   ETBAR\n",
    "        \n",
    "        z1 = self.fc3(z)    ####  DT\n",
    "        z2 = F.linear(z1, self.fc3.weight.t())    #### DTBAR\n",
    "\n",
    "        \n",
    "        w = torch.stack((x, x2,z, z2), dim=2)\n",
    "        v = torch.cat((y2,y3),dim =2)\n",
    "        u = torch.cat((w,v),dim=2)\n",
    "        a = a.view(-1,50,1)\n",
    "        r = torch.cat((a,u),dim = 2)\n",
    "        \n",
    "        r = r.view(-1,1,50,5+2*(filters))\n",
    "        t = self.conv4(r)\n",
    "        s = t.view(-1,50)\n",
    "\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([32, 50], dtype=torch.float64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M5PLdzGYrDO"
   },
   "outputs": [],
   "source": [
    "model = DNN_f()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import log_loss\n",
    "# custom function\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# define vectorized sigmoid\n",
    "sigmoid_v = np.vectorize(sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYXUuJAjYrDQ"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "loss_func = nn.BCEWithLogitsLoss(reduction = 'mean').cuda()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loss = 0\n",
    "losses = []\n",
    "steps = []\n",
    "step = 0\n",
    "count = 0\n",
    "EPOCHS = 50\n",
    "trained = []\n",
    "tested = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_indicator = torch.ones([107017, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKAPwzquMI6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  50\n",
      "3344/3344.28125 loss: 0.042608323653697724 \n",
      "--- 803.8426699638367 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "train_dataset = TensorDataset(X_freq, X_recent, X_recommend, y, X_indicator)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    model.train()\n",
    "    for step_num, batch_data in enumerate(train_dataloader):\n",
    "        freq, recent, recommend, labels, indicator = tuple(t.to(device)for t in batch_data)\n",
    "        probas = model(freq, recent, recommend, indicator)\n",
    "        batch_loss = loss_func(probas, labels)\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "\n",
    "\n",
    "        #clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print('Epoch: ', epoch_num + 1)\n",
    "        print(\"{0}/{1} loss: {2} \".format(step_num, len(y)/BATCH_SIZE, train_loss / (count + 1)))\n",
    "        print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        losses.append(batch_loss.item())\n",
    "        steps.append(step)\n",
    "        step += 1\n",
    "        count += 1\n",
    "#     lg_train = model(X_freq.to(device), X_recent.to(device), X_recommend.to(device), X_indicator.to(device)).to('cpu')\n",
    "#     numpy_lg_train = lg_train.detach().numpy()\n",
    "#     prob_tr = sigmoid_v(numpy_lg_train)\n",
    "#     trained.append(log_loss(y.numpy(),prob_tr))\n",
    "#     lg_test = model(X_freq_test.to(device), X_recent_test.to(device), X_recommend_test.to(device), X_indicator.to(device)).to('cpu')\n",
    "#     numpy_lg_test = lg_test.detach().numpy()\n",
    "#     prob_tt = sigmoid_v(numpy_lg_test)\n",
    "#     tested.append(log_loss(Y_test.numpy(),prob_tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model_dnn_march30_12743.pkl\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    logits_train = model(X_freq.to(device), X_recent.to(device), X_recommend.to(device), X_indicator.to(device)).to('cpu')\n",
    "    logits_test = model(X_freq_test.to(device), X_recent_test.to(device), X_recommend_test.to(device), X_indicator.to(device)).to('cpu')\n",
    "    numpy_logits_train = logits_train.detach().numpy()\n",
    "    numpy_logits_test = logits_test.detach().numpy()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting logits to probabilities\n",
    "numpy_probas_test = sigmoid_v(numpy_logits_test)\n",
    "numpy_probas_train = sigmoid_v(numpy_logits_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.095926663173644"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test.numpy(),numpy_probas_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = []\n",
    "roc = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), numpy_probas_test[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    roc.append(roc_auc)\n",
    "    thresh.append(optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972899944806862"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(roc)/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "\treturn (pos_probs >= threshold).astype('int')\n",
    "\n",
    "for i in range(50):\n",
    "    numpy_probas_test[:,i] = to_labels(numpy_probas_test[:,i],thresh[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[100736,   5483],\n",
       "        [    98,    700]],\n",
       "\n",
       "       [[ 74843,  31941],\n",
       "        [    19,    214]],\n",
       "\n",
       "       [[ 83876,  22982],\n",
       "        [    34,    125]],\n",
       "\n",
       "       [[ 97838,   8577],\n",
       "        [    93,    509]],\n",
       "\n",
       "       [[ 81226,  23723],\n",
       "        [   465,   1603]],\n",
       "\n",
       "       [[ 85239,  20306],\n",
       "        [   246,   1226]],\n",
       "\n",
       "       [[ 91839,  15140],\n",
       "        [    10,     28]],\n",
       "\n",
       "       [[ 80503,  23987],\n",
       "        [   332,   2195]],\n",
       "\n",
       "       [[ 77521,  28976],\n",
       "        [    95,    425]],\n",
       "\n",
       "       [[ 81851,  14214],\n",
       "        [   759,  10193]],\n",
       "\n",
       "       [[ 94977,  11861],\n",
       "        [    57,    122]],\n",
       "\n",
       "       [[ 87597,  17897],\n",
       "        [   171,   1352]],\n",
       "\n",
       "       [[ 85873,  21107],\n",
       "        [    12,     25]],\n",
       "\n",
       "       [[ 90741,  15067],\n",
       "        [   329,    880]],\n",
       "\n",
       "       [[ 98217,   8150],\n",
       "        [   107,    543]],\n",
       "\n",
       "       [[ 79739,  27152],\n",
       "        [    33,     93]],\n",
       "\n",
       "       [[ 71264,  35702],\n",
       "        [     8,     43]],\n",
       "\n",
       "       [[ 85034,  18729],\n",
       "        [   355,   2899]],\n",
       "\n",
       "       [[ 85758,  20612],\n",
       "        [    52,    595]],\n",
       "\n",
       "       [[ 95037,  11881],\n",
       "        [    18,     81]],\n",
       "\n",
       "       [[ 91148,  15602],\n",
       "        [    25,    242]],\n",
       "\n",
       "       [[ 85505,  19028],\n",
       "        [   265,   2219]],\n",
       "\n",
       "       [[ 72111,  34884],\n",
       "        [     2,     20]],\n",
       "\n",
       "       [[ 86759,  20120],\n",
       "        [    11,    127]],\n",
       "\n",
       "       [[ 84770,  22154],\n",
       "        [    11,     82]],\n",
       "\n",
       "       [[ 63482,  43523],\n",
       "        [     0,     12]],\n",
       "\n",
       "       [[ 82127,  23278],\n",
       "        [   207,   1405]],\n",
       "\n",
       "       [[ 79666,  27246],\n",
       "        [    18,     87]],\n",
       "\n",
       "       [[ 58742,  48230],\n",
       "        [     0,     45]],\n",
       "\n",
       "       [[ 71575,  30291],\n",
       "        [  1001,   4150]],\n",
       "\n",
       "       [[ 88439,  18494],\n",
       "        [    12,     72]],\n",
       "\n",
       "       [[ 80802,  26035],\n",
       "        [    17,    163]],\n",
       "\n",
       "       [[ 87300,  18424],\n",
       "        [   244,   1049]],\n",
       "\n",
       "       [[ 84826,  21895],\n",
       "        [    45,    251]],\n",
       "\n",
       "       [[ 83067,  21930],\n",
       "        [   462,   1558]],\n",
       "\n",
       "       [[ 86417,  18025],\n",
       "        [   233,   2342]],\n",
       "\n",
       "       [[ 90151,  16818],\n",
       "        [     8,     40]],\n",
       "\n",
       "       [[ 84894,  22059],\n",
       "        [     9,     55]],\n",
       "\n",
       "       [[ 84297,  22040],\n",
       "        [   123,    557]],\n",
       "\n",
       "       [[ 76120,  30880],\n",
       "        [     1,     16]],\n",
       "\n",
       "       [[ 85695,  21190],\n",
       "        [     8,    124]],\n",
       "\n",
       "       [[ 88049,  18364],\n",
       "        [   160,    444]],\n",
       "\n",
       "       [[ 82097,  24747],\n",
       "        [    10,    163]],\n",
       "\n",
       "       [[ 86462,  20330],\n",
       "        [    26,    199]],\n",
       "\n",
       "       [[ 84402,  22544],\n",
       "        [     6,     65]],\n",
       "\n",
       "       [[104094,   1610],\n",
       "        [   114,   1199]],\n",
       "\n",
       "       [[ 82237,  24761],\n",
       "        [     2,     17]],\n",
       "\n",
       "       [[ 77377,  29462],\n",
       "        [    24,    154]],\n",
       "\n",
       "       [[ 98389,   8527],\n",
       "        [    13,     88]],\n",
       "\n",
       "       [[ 85898,  19388],\n",
       "        [   107,   1624]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(Y_test.numpy(), numpy_probas_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting engagement frequencies from tensor to numpy array\n",
    "\n",
    "X_freq_1 = X_freq.numpy()\n",
    "X_freq_1_test = X_freq_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_train_p = []\n",
    "empty_test_p = []\n",
    "for i in range(50):\n",
    "    recent_lm_train = X_recent_2[:,[i,i+50,i+100,i+150]]     #Engagement history by topic as input for training\n",
    "    freq_lm_train = X_freq_1[:,i]                            #Engagement frequncy by topic as input for training\n",
    "    recommend_lm_train = X_recommend_1[:,i]                  #Recommendations by topic as input for training\n",
    "    \n",
    "    recent_lm_test = X_recent_2_test[:,[i,i+50,i+100,i+150]] #Engagement history by topic as input for testing\n",
    "    freq_lm_test = X_freq_1_test[:,i]                        #Engagement frequncy by topic as input for testing\n",
    "    recommend_lm_test = X_recommend_t[:,i]                   #Recommendations by topic as input for testing\n",
    "\n",
    "\n",
    "    y_lm_train = y_1[:,i]                                    #Engagement labels\n",
    "\n",
    "    X = np.column_stack([recent_lm_train,freq_lm_train,recommend_lm_train])  #Concatenated input features for training\n",
    "\n",
    "    #LR = LogisticRegression(class_weight=\"balanced\")\n",
    "    LR = LogisticRegression()\n",
    "\n",
    "    LR.fit(X,y_lm_train)\n",
    "    \n",
    "    X_test = np.column_stack([recent_lm_test,freq_lm_test,recommend_lm_test]) #Concatenated input features for testing\n",
    "    \n",
    "    empty_train_p.append((LR.predict_proba(X)[:,1]))\n",
    "       \n",
    "    empty_test_p.append((LR.predict_proba(X_test)[:,1]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr_train_p = np.transpose(np.array(empty_train_p))  #Predictions for training data\n",
    "prediction_lr_test_p = np.transpose(np.array(empty_test_p))    #Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1467783394645972"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(y_t,prediction_lr_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "thresh_lr = []\n",
    "roc_lr = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), prediction_lr_test_p[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    thresh_lr.append(optimal_threshold)\n",
    "    roc_lr.append(roc_auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061488027555269"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(roc_lr)/50  #Average AUC-ROC score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lr_test_p = np.empty([107017, 50])\n",
    "for i in range(50):\n",
    "    label_lr_test_p[:,i] = to_labels(prediction_lr_test_p[:,i],thresh_lr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[102417,   3802],\n",
       "        [     0,    798]],\n",
       "\n",
       "       [[105775,   1009],\n",
       "        [     0,    233]],\n",
       "\n",
       "       [[105828,   1030],\n",
       "        [     0,    159]],\n",
       "\n",
       "       [[104243,   2172],\n",
       "        [     0,    602]],\n",
       "\n",
       "       [[ 94174,  10775],\n",
       "        [     0,   2068]],\n",
       "\n",
       "       [[102158,   3387],\n",
       "        [     0,   1472]],\n",
       "\n",
       "       [[106677,    302],\n",
       "        [     0,     38]],\n",
       "\n",
       "       [[ 92050,  12440],\n",
       "        [     0,   2527]],\n",
       "\n",
       "       [[ 98068,   8429],\n",
       "        [     0,    520]],\n",
       "\n",
       "       [[ 81224,  14841],\n",
       "        [     0,  10952]],\n",
       "\n",
       "       [[105311,   1527],\n",
       "        [     0,    179]],\n",
       "\n",
       "       [[100687,   4807],\n",
       "        [     0,   1523]],\n",
       "\n",
       "       [[106664,    316],\n",
       "        [    36,      1]],\n",
       "\n",
       "       [[ 99024,   6784],\n",
       "        [     0,   1209]],\n",
       "\n",
       "       [[ 99346,   7021],\n",
       "        [     0,    650]],\n",
       "\n",
       "       [[105812,   1079],\n",
       "        [     0,    126]],\n",
       "\n",
       "       [[106966,      0],\n",
       "        [    51,      0]],\n",
       "\n",
       "       [[ 91373,  12390],\n",
       "        [     0,   3254]],\n",
       "\n",
       "       [[100715,   5655],\n",
       "        [     0,    647]],\n",
       "\n",
       "       [[105825,   1093],\n",
       "        [     0,     99]],\n",
       "\n",
       "       [[106290,    460],\n",
       "        [     0,    267]],\n",
       "\n",
       "       [[ 95826,   8707],\n",
       "        [     0,   2484]],\n",
       "\n",
       "       [[106988,      7],\n",
       "        [     0,     22]],\n",
       "\n",
       "       [[106493,    386],\n",
       "        [     0,    138]],\n",
       "\n",
       "       [[106889,     35],\n",
       "        [     0,     93]],\n",
       "\n",
       "       [[106848,    157],\n",
       "        [    11,      1]],\n",
       "\n",
       "       [[ 98766,   6639],\n",
       "        [     0,   1612]],\n",
       "\n",
       "       [[106638,    274],\n",
       "        [     0,    105]],\n",
       "\n",
       "       [[105692,   1280],\n",
       "        [    39,      6]],\n",
       "\n",
       "       [[ 78867,  22999],\n",
       "        [     0,   5151]],\n",
       "\n",
       "       [[106933,      0],\n",
       "        [    84,      0]],\n",
       "\n",
       "       [[106107,    730],\n",
       "        [     0,    180]],\n",
       "\n",
       "       [[ 98458,   7266],\n",
       "        [     0,   1293]],\n",
       "\n",
       "       [[105410,   1311],\n",
       "        [     0,    296]],\n",
       "\n",
       "       [[ 92103,  12894],\n",
       "        [     0,   2020]],\n",
       "\n",
       "       [[ 92743,  11699],\n",
       "        [     0,   2575]],\n",
       "\n",
       "       [[106443,    526],\n",
       "        [     0,     48]],\n",
       "\n",
       "       [[106953,      0],\n",
       "        [    64,      0]],\n",
       "\n",
       "       [[100892,   5445],\n",
       "        [     0,    680]],\n",
       "\n",
       "       [[106235,    765],\n",
       "        [    15,      2]],\n",
       "\n",
       "       [[106051,    834],\n",
       "        [     0,    132]],\n",
       "\n",
       "       [[103054,   3359],\n",
       "        [     0,    604]],\n",
       "\n",
       "       [[105483,   1361],\n",
       "        [     0,    173]],\n",
       "\n",
       "       [[105339,   1453],\n",
       "        [     0,    225]],\n",
       "\n",
       "       [[   107, 106839],\n",
       "        [     0,     71]],\n",
       "\n",
       "       [[103161,   2543],\n",
       "        [     0,   1313]],\n",
       "\n",
       "       [[106907,     91],\n",
       "        [    18,      1]],\n",
       "\n",
       "       [[105367,   1472],\n",
       "        [     0,    178]],\n",
       "\n",
       "       [[106008,    908],\n",
       "        [     0,    101]],\n",
       "\n",
       "       [[ 93578,  11708],\n",
       "        [     0,   1731]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(Y_test.numpy(), label_lr_test_p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_train_1p = []\n",
    "empty_test_1p = []\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    recent_lm_train = X_recent_2[:,[i,i+50,i+100,i+150]]\n",
    "    freq_lm_train = X_freq_1[:,i]\n",
    "    recommend_lm_train = X_recommend_1[:,i]\n",
    "    \n",
    "    recent_lm_test = X_recent_2_test[:,[i,i+50,i+100,i+150]]\n",
    "    freq_lm_test = X_freq_1_test[:,i]\n",
    "    recommend_lm_test = X_recommend_t[:,i]\n",
    "\n",
    "\n",
    "    y_lm_train = y_1[:,i]\n",
    "    \n",
    "\n",
    "    X = np.column_stack([recent_lm_train,freq_lm_train,recommend_lm_train])\n",
    "\n",
    "    LGBM = LGBMClassifier()\n",
    "\n",
    "    LGBM.fit(X,y_lm_train)\n",
    "    \n",
    "    X_test = np.column_stack([recent_lm_test,freq_lm_test,recommend_lm_test])\n",
    "    \n",
    "    empty_train_1p.append((LGBM.predict_proba(X)[:,1]))\n",
    "\n",
    "    empty_test_1p.append((LGBM.predict_proba(X_test)[:,1]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgbm_train_p = np.transpose(np.array(empty_train_1p))\n",
    "prediction_lgbm_test_p = np.transpose(np.array(empty_test_1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1886555611206588"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test.numpy(),prediction_lgbm_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_lgbm = []\n",
    "roc_lgbm = []\n",
    "for i in range(50):    \n",
    "    import sklearn.metrics as metrics\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    #probs = model.predict_proba(X_test)\n",
    "    #preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(Y_test[:,i].numpy(), prediction_lgbm_test_p[:,i])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    thresh_lgbm.append(optimal_threshold)\n",
    "    roc_lgbm.append(roc_auc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451390615155378"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(roc_lgbm)/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_lgbm_test_p = np.empty([107017, 50])\n",
    "for i in range(50):\n",
    "    label_lgbm_test_p[:,i] = to_labels(prediction_lgbm_test_p[:,i],thresh_lgbm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[102684,   3535],\n",
       "        [     2,    796]],\n",
       "\n",
       "       [[105947,    837],\n",
       "        [   223,     10]],\n",
       "\n",
       "       [[106240,    618],\n",
       "        [   156,      3]],\n",
       "\n",
       "       [[104074,   2341],\n",
       "        [    11,    591]],\n",
       "\n",
       "       [[ 90466,  14483],\n",
       "        [    12,   2056]],\n",
       "\n",
       "       [[101831,   3714],\n",
       "        [    19,   1453]],\n",
       "\n",
       "       [[   272, 106707],\n",
       "        [     0,     38]],\n",
       "\n",
       "       [[ 91043,  13447],\n",
       "        [    11,   2516]],\n",
       "\n",
       "       [[ 97113,   9384],\n",
       "        [   288,    232]],\n",
       "\n",
       "       [[ 82736,  13329],\n",
       "        [    33,  10919]],\n",
       "\n",
       "       [[106828,     10],\n",
       "        [   146,     33]],\n",
       "\n",
       "       [[ 96988,   8506],\n",
       "        [     4,   1519]],\n",
       "\n",
       "       [[   244, 106736],\n",
       "        [     0,     37]],\n",
       "\n",
       "       [[ 98242,   7566],\n",
       "        [     3,   1206]],\n",
       "\n",
       "       [[100455,   5912],\n",
       "        [     5,    645]],\n",
       "\n",
       "       [[106783,    108],\n",
       "        [    26,    100]],\n",
       "\n",
       "       [[   211, 106755],\n",
       "        [     0,     51]],\n",
       "\n",
       "       [[ 90293,  13470],\n",
       "        [    11,   3243]],\n",
       "\n",
       "       [[ 98647,   7723],\n",
       "        [     5,    642]],\n",
       "\n",
       "       [[106575,    343],\n",
       "        [    81,     18]],\n",
       "\n",
       "       [[106595,    155],\n",
       "        [    29,    238]],\n",
       "\n",
       "       [[ 93296,  11237],\n",
       "        [     2,   2482]],\n",
       "\n",
       "       [[   159, 106836],\n",
       "        [     0,     22]],\n",
       "\n",
       "       [[106623,    256],\n",
       "        [   134,      4]],\n",
       "\n",
       "       [[    86, 106838],\n",
       "        [     0,     93]],\n",
       "\n",
       "       [[   634, 106371],\n",
       "        [     0,     12]],\n",
       "\n",
       "       [[ 96046,   9359],\n",
       "        [     9,   1603]],\n",
       "\n",
       "       [[106912,      0],\n",
       "        [   105,      0]],\n",
       "\n",
       "       [[    31, 106941],\n",
       "        [     0,     45]],\n",
       "\n",
       "       [[ 76676,  25190],\n",
       "        [    37,   5114]],\n",
       "\n",
       "       [[106933,      0],\n",
       "        [    84,      0]],\n",
       "\n",
       "       [[106772,     65],\n",
       "        [    17,    163]],\n",
       "\n",
       "       [[ 96553,   9171],\n",
       "        [     2,   1291]],\n",
       "\n",
       "       [[105889,    832],\n",
       "        [    58,    238]],\n",
       "\n",
       "       [[ 90588,  14409],\n",
       "        [    16,   2004]],\n",
       "\n",
       "       [[ 92235,  12207],\n",
       "        [    17,   2558]],\n",
       "\n",
       "       [[   648, 106321],\n",
       "        [     0,     48]],\n",
       "\n",
       "       [[   392, 106561],\n",
       "        [     0,     64]],\n",
       "\n",
       "       [[100192,   6145],\n",
       "        [     0,    680]],\n",
       "\n",
       "       [[   308, 106692],\n",
       "        [     0,     17]],\n",
       "\n",
       "       [[106554,    331],\n",
       "        [    17,    115]],\n",
       "\n",
       "       [[102042,   4371],\n",
       "        [   396,    208]],\n",
       "\n",
       "       [[105620,   1224],\n",
       "        [    27,    146]],\n",
       "\n",
       "       [[103281,   3511],\n",
       "        [   160,     65]],\n",
       "\n",
       "       [[   193, 106753],\n",
       "        [     0,     71]],\n",
       "\n",
       "       [[104069,   1635],\n",
       "        [   114,   1199]],\n",
       "\n",
       "       [[   559, 106439],\n",
       "        [     0,     19]],\n",
       "\n",
       "       [[106335,    504],\n",
       "        [   163,     15]],\n",
       "\n",
       "       [[106911,      5],\n",
       "        [    97,      4]],\n",
       "\n",
       "       [[ 91451,  13835],\n",
       "        [     3,   1728]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(Y_test.numpy(), label_lgbm_test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive search for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(X_recommend_t)\n",
    "x.sum(axis=1).value_counts()\n",
    "x['Total'] = x.sum(axis=1)\n",
    "y=x[x['Total'] >= 6] #Considering only the users who are shown atleast six tweets\n",
    "#del y['Total']\n",
    "\n",
    "infinity = pd.DataFrame(X_freq_1_test)\n",
    "histo = pd.DataFrame(X_recent_2_test)\n",
    "\n",
    "inf_new=infinity.loc[y.index,:]\n",
    "hist_new=histo.loc[y.index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(freq, hist, y):\n",
    "    empty =[]\n",
    "    for user in range(y.shape[0]):\n",
    "        s=set()\n",
    "        for i,x in enumerate(y.iloc[user]):\n",
    "            if x==1.0:\n",
    "                s.add(i)\n",
    "        output=[[0.0]*50]\n",
    "        removed=set()\n",
    "        l_=[]\n",
    "\n",
    "        for j in range(5):\n",
    "            ma=-float('inf')\n",
    "            for i in s:\n",
    "                l_.append(i)\n",
    "\n",
    "                output[0][i]=1.0\n",
    "                inf_new_ = torch.FloatTensor(freq.iloc[user].values).reshape(1,50)\n",
    "                hist_new_ = torch.FloatTensor(hist.iloc[user].values.reshape(-1,50,4))\n",
    "                y_ = torch.FloatTensor(np.array(output[0])).reshape(1,50)\n",
    "                indicator = torch.ones([50]).reshape(1,50)    \n",
    "                logits_opt = model(inf_new_.to(device), hist_new_.to(device), y_.to(device), indicator.to(device))\n",
    "                numpy_logits_opt = logits_opt.to('cpu').detach().numpy()\n",
    "                numpy_probas_opt = sigmoid_v(numpy_logits_opt)\n",
    "                sum_=sum(numpy_probas_opt[0][k] for k in l_)\n",
    "                if sum_>ma:\n",
    "                    result_l=l_[:]\n",
    "                    numpy_logits_opt_max=numpy_logits_opt\n",
    "                    numpy_probas_opt_max=numpy_probas_opt\n",
    "                    ma=sum_\n",
    "                    index=i\n",
    "                l_.pop()\n",
    "                output[0][i]=0.0\n",
    "\n",
    "            output[0][index]=1.0\n",
    "            l_.append(index)\n",
    "\n",
    "            s.remove(index)\n",
    "        empty.append([y.index[user],ma,result_l])\n",
    "    n=pd.DataFrame(empty,columns=['USER','MAX_SUM','LIST_OF_INDEX'])\n",
    "    return (n['MAX_SUM'].mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.677213976646597"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(inf_new, hist_new, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift score obtained using combination of topics a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob : output probabilities for a given model\n",
    "#y : input recommendations considering overall timeline\n",
    "#freq: engagement frequency\n",
    "#hist: engagement history\n",
    "\n",
    "def uplift_score(prob, freq, hist, y):     \n",
    "    mdl = pd.DataFrame(prob)\n",
    "    mdl_y = mdl.loc[y.index]\n",
    "    p = mdl_y*y.iloc[:,0:50].values\n",
    "    s=pd.DataFrame(np.zeros((p.shape[0],p.shape[1]))).set_index(p.index)\n",
    "    for ind in p.index:\n",
    "        s.loc[ind,p.loc[ind].nlargest(5).index.values]=1\n",
    "    s_=s.reset_index()\n",
    "    s_.index = s_['index']\n",
    "    del s_['index']\n",
    "    inf_new_T = torch.FloatTensor(freq.values)\n",
    "    hist_new_T = torch.FloatTensor(hist.values.reshape(-1,50,4))\n",
    "    rec_T = torch.FloatTensor(s_.values)\n",
    "    indicator_T = torch.ones([len(rec_T), 50])\n",
    "    logits_opt = model(inf_new_T.to(device), hist_new_T.to(device), rec_T.to(device), indicator_T.to(device))\n",
    "    numpy_logits_opt = logits_opt.to('cpu').detach().numpy()\n",
    "    numpy_probas_opt = sigmoid_v(numpy_logits_opt)\n",
    "    sp = pd.DataFrame(numpy_probas_opt, index = y.index)\n",
    "    sc = sp*s_.values\n",
    "    return(sc.sum(axis = 1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448964056409812"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplift_score(prediction_lr_test_p,inf_new, hist_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6368377623062471"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uplift_score(prediction_lgbm_test_p,inf_new, hist_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Product_choice_model_bucketing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
